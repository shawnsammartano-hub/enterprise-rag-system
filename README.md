# Enterprise RAG System - Production-Ready Implementation

A production-grade Retrieval-Augmented Generation (RAG) pipeline demonstrating enterprise AI architecture patterns used by Databricks, Snowflake, and leading fintech companies.

![RAG Architecture](https://img.shields.io/badge/RAG-Production%20Ready-green)
![Python](https://img.shields.io/badge/Python-3.12-blue)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ğŸ¯ Business Context

Built to demonstrate AI enablement capabilities for financial services enterprise environments. Showcases understanding of:
- Vector search architectures (like Databricks Vector Search)
- Semantic embeddings (like Snowflake Cortex)
- Enterprise RAG patterns for document Q&A
- Production deployment considerations

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   User Interface (Streamlit)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAG Pipeline Layer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Document   â”‚  â”‚   Chunking   â”‚  â”‚  Embedding   â”‚      â”‚
â”‚  â”‚   Ingestion  â”‚â†’ â”‚   Strategy   â”‚â†’ â”‚  Generation  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Vector Database (ChromaDB)                      â”‚
â”‚         Persistent Storage with Semantic Search              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Retrieval & Re-ranking                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Hybrid     â”‚  â”‚  Metadata    â”‚  â”‚   Re-rank    â”‚      â”‚
â”‚  â”‚   Search     â”‚â†’ â”‚  Filtering   â”‚â†’ â”‚  Top Results â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LLM Generation (Ollama/Llama 3.1)              â”‚
â”‚           Context-Aware Answer Synthesis                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

### Core Capabilities
- âœ… **Multi-format ingestion**: PDF (with OCR), DOCX, TXT
- âœ… **Semantic search**: 768-dimensional embeddings (nomic-embed-text)
- âœ… **Hybrid retrieval**: Vector (70%) + BM25 keyword (30%)
- âœ… **Smart chunking**: 500-word chunks with 10% overlap
- âœ… **Metadata filtering**: SQL-like queries on document attributes
- âœ… **Two-stage re-ranking**: Fast retrieval + precision scoring
- âœ… **Local LLM**: Privacy-first with Ollama (Llama 3.1)
- âœ… **Web interface**: Production-ready Streamlit UI

### Advanced Features
- **OCR Support**: Tesseract integration for scanned documents
- **Persistent Storage**: ChromaDB with disk-based persistence
- **Citation Tracking**: Source attribution for all answers
- **Configurable Parameters**: Chunk size, retrieval count, alpha weighting
- **Performance Monitoring**: Query latency and token throughput metrics

## ğŸš€ Quick Start

### Prerequisites
```bash
# System requirements
- Python 3.12+
- 8GB RAM minimum
- Ubuntu 24.04 or WSL2

# Ollama with models
ollama pull llama3.1:8b
ollama pull nomic-embed-text
```

### Installation
```bash
# Clone repository
git clone https://github.com/shawnsammartano-hub/enterprise-rag-system.git
cd enterprise-rag-system

# Install dependencies
pip install -r requirements.txt

# Install OCR support
sudo apt install tesseract-ocr poppler-utils -y

# Launch web interface
streamlit run app.py
```

### Docker Deployment (Coming Soon)
```bash
docker-compose up -d
```

## ğŸ“Š Performance Metrics

| Metric | Value | Context |
|--------|-------|---------|
| Embedding Speed | 787 tokens/sec | nomic-embed-text (768 dims) |
| Query Latency | ~15-20s | CPU inference (AMD Radeon) |
| Chunk Processing | 42 chunks from 116-page PDF | With OCR |
| Storage Efficiency | ~3GB per 1M documents | 768-dimensional vectors |

## ğŸ“ Enterprise Patterns Demonstrated

### 1. Hybrid Search
```python
# 70% semantic, 30% keyword matching
result = rag.hybrid_query(
    question="What is Snowflake used for?",
    alpha=0.7  # Enterprise default
)
```

**Why**: Pure vector search misses exact terms (SKUs, IDs), pure keyword misses synonyms.

### 2. Chunking Strategy
```python
# 500 words with 10% overlap
chunks = rag.chunk_text(
    text=document,
    chunk_size=500,
    overlap=50
)
```

**Why**: Balances context preservation with retrieval precision. Matches Databricks defaults.

### 3. Metadata Filtering
```python
# Filter by document attributes
result = rag.query_with_filter(
    question="Recent policy updates?",
    metadata_filter={"department": "Legal", "year": {"$gte": 2024}}
)
```

**Why**: Reduces search space, improves relevance. Like Databricks partition pruning.

### 4. Two-Stage Re-ranking
```python
# Retrieve 10, re-rank to top 3
result = rag.query_with_reranking(
    question="What are our Q2 goals?",
    initial_results=10,
    final_results=3
)
```

**Why**: Fast first-pass retrieval, expensive precision scoring only on candidates.

## ğŸ¢ Enterprise Mapping

| This System | Databricks | Snowflake | Azure |
|-------------|-----------|-----------|-------|
| ChromaDB | Vector Search | Cortex Search | AI Search |
| nomic-embed-text | instructor-xl | E5-large | text-embedding-ada |
| Hybrid Search | Delta + Vector | UDF + Vector | Hybrid Retrieval |
| Llama 3.1 | DBRX/Llama | Mistral/Llama | GPT-4 |

## ğŸ“ Project Structure
```
enterprise-rag-system/
â”œâ”€â”€ app.py                      # Streamlit web interface
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ rag_pipeline.py        # Core RAG implementation
â”‚   â”œâ”€â”€ hybrid_search.py       # Vector + BM25 hybrid
â”‚   â”œâ”€â”€ reranking.py           # Two-stage retrieval
â”‚   â”œâ”€â”€ metadata_filtering.py  # Attribute-based filtering
â”‚   â”œâ”€â”€ chunking_analysis.py   # Strategy comparison
â”‚   â””â”€â”€ embedding_comparison.py # Model benchmarking
â”œâ”€â”€ documents/                  # Sample documents
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # This file
```

## ğŸ”§ Configuration
```python
# ~/.rag_pipeline/chromadb/
# Persistent vector database storage

# Key parameters
EMBEDDING_MODEL = "nomic-embed-text"  # 768 dimensions
LLM_MODEL = "llama3.1-32k"            # 32K context window
CHUNK_SIZE = 500                       # words
CHUNK_OVERLAP = 50                     # 10% overlap
ALPHA = 0.7                            # Hybrid search weight
```

## ğŸ“ˆ Use Cases

### Financial Services
- Client onboarding documentation
- Compliance policy Q&A
- Product knowledge base
- Risk assessment reports

### Technology Companies
- API documentation search
- Internal wiki/knowledge base
- Technical runbooks
- Incident post-mortems

### Healthcare
- Clinical guidelines
- Research paper analysis
- Patient education materials
- Protocol documentation

## ğŸ› ï¸ Development
```bash
# Run tests
pytest tests/

# Benchmark performance
python scripts/embedding_comparison.py

# Analyze chunking strategies
python scripts/chunking_analysis.py

# Compare search methods
python scripts/hybrid_search.py
```

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ™ Acknowledgments

- Built with [LangChain](https://langchain.com), [ChromaDB](https://www.trychroma.com), [Ollama](https://ollama.ai)
- Embedding model: [nomic-embed-text](https://huggingface.co/nomic-ai/nomic-embed-text-v1)
- LLM: [Llama 3.1](https://ai.meta.com/llama/) by Meta

## ğŸ“§ Contact

Built by: Shawn Sammartano 
Portfolio: [Your Portfolio URL] (https://shawnsammartano-hub.github.io/data-driven-csm/) 
LinkedIn: [Your LinkedIn] (https://www.linkedin.com/in/shawnsammartano/)
Purpose: AI Enablement demonstration

---

**Note**: This is a demonstration system. For production deployment, consider:
- Authentication & authorization
- Rate limiting & quotas
- Horizontal scaling (vector DB sharding)
- Monitoring & observability (Datadog, Prometheus)
- CI/CD pipelines
- Security scanning
- Backup & disaster recovery
